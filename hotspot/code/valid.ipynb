{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from package.utils import KPIPoint\n",
    "from package.utils import KPISet\n",
    "from package.utils import Transformer\n",
    "from package.HotSpot import HotSpot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载第一周数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timestamp_strat = 1535731200\n",
    "timestamp_end = 1536335700 #1535731200 + 5 * 60#\n",
    "timestamp_interval = 5 * 60\n",
    "file_path = '../2019AIOps_data/'\n",
    "kSet_train = Transformer().transformKPIData2KPISet(file_path, timestamp_strat, timestamp_end, timestamp_interval)\n",
    "kSet_train.save('../result/metadata/KPISetTrain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载第二周数据（注入了异常）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timestamp_strat = 1536336000\n",
    "timestamp_end = 1536940500 #1536336000 + 5 * 60# \n",
    "timestamp_interval = 5 * 60\n",
    "file_path = '../2019AIOps_data_valid/'\n",
    "kSet_valid = Transformer().transformKPIData2KPISet(file_path, timestamp_strat, timestamp_end, timestamp_interval)\n",
    "kSet_valid.save('../result/metadata/KPISetValid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用第一周数据预测第二周数据，此处可以优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 使用第一周数据预测第二周数据\n",
    "I = 300\n",
    "T = I * 288\n",
    "train_timestamp_start = 1535731200\n",
    "train_timestamp_end = 1536335700\n",
    "for timestamp in tqdm(kSet_valid._KPIPoints):\n",
    "    tw = math.floor((timestamp - 16 * 3600) % (3600 * 24) / I)\n",
    "    # print(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(timestamp)), tw)\n",
    "    for leaf in kSet_valid._KPIPoints[timestamp]._leaf:\n",
    "        ts_true = kSet_train.get_ts_leaf(leaf=leaf, \n",
    "                                         t1=train_timestamp_start + tw * I,\n",
    "                                         t2=train_timestamp_end, \n",
    "                                         delta=T)['true']\n",
    "        predict = np.mean(ts_true)\n",
    "        kSet_valid._KPIPoints[timestamp]._leaf[leaf][1] = predict\n",
    "\n",
    "#### 保存数据\n",
    "kSet_valid.save('../result/metadata/KPISetValidPredict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 异常定位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "# kSet_valid = KPISet({}, {})\n",
    "# kSet_valid.load('../result/metadata/KPISetValidPredict')\n",
    "\n",
    "# 读取异常时间戳\n",
    "outlier = pd.read_csv('../Anomalytime_data_valid.csv')\n",
    "outlier = outlier['timestamp'].tolist()\n",
    "\n",
    "# HotSpot参数\n",
    "ps_threshold = 0.98  # 潜在得分阈值\n",
    "ep_threshold = 0.01  # 解释力阈值\n",
    "max_iter = 10  # MCTS最大迭代次数\n",
    "\n",
    "res = {}\n",
    "res['timestamp'] = []\n",
    "res['set'] = []\n",
    "sTime = time.time()\n",
    "for timestamp in tqdm(outlier):\n",
    "    ts = timestamp / 1000\n",
    "    kPoint = kSet_valid._KPIPoints[ts]\n",
    "    layer_max = len(kPoint._attribute_names)\n",
    "    hotSpot = HotSpot(kPoint, layer_max, ps_threshold, ep_threshold, max_iter)\n",
    "    rootCauseSet = hotSpot.find_root_cause_set_revised()\n",
    "    res['timestamp'].append(timestamp)\n",
    "    sets = []\n",
    "    for ele in rootCauseSet[0][0]:\n",
    "        sets.append(\"&\".join(ele))\n",
    "    res['set'].append(';'.join(sets))\n",
    "eTime = time.time()\n",
    "print('runtime %fs' % (eTime - sTime))\n",
    "res = pd.DataFrame(res)\n",
    "resPath = '../result/submit_valid_%s.csv' % time.strftime(\"%Y%m%d%H%M%S\", time.localtime(eTime))\n",
    "res.to_csv(resPath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取异常时间戳，注意该文件带有Header——timestamp\n",
    "root_cause_set = pd.read_csv('../Anomalytime_data_valid.csv')\n",
    "root_cause_set = root_cause_set.sort_values(by='timestamp').reset_index(drop=True)\n",
    "root_cause_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isset(v):\n",
    "    try:\n",
    "        type (eval(v))\n",
    "    except:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def transformRootCauseSet(string):\n",
    "    root_cause_set = []\n",
    "    sets = string.split(';')\n",
    "    for s in sets:\n",
    "        elements = s.split('&')\n",
    "        root_cause_set.append(elements)\n",
    "    return root_cause_set\n",
    "resPath = resPath if isset('resPath') else '../result/submit_valid.csv'\n",
    "result = pd.read_csv(resPath)\n",
    "result = result.sort_values(by='timestamp').reset_index(drop=True)\n",
    "result['set'] = result['set'].apply(transformRootCauseSet)\n",
    "result = result.merge(root_cause_set, on='timestamp', how='left')\n",
    "result.to_csv('../result/root_cause_set_valid_%s.csv' % time.strftime(\"%Y%m%d%H%M%S\", time.localtime(time.time())), \n",
    "              index=False)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 计算F-score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 评估准确性的指标是F-score,该指标是准确率（Precision）和召回率(Recall)综合体现。具体计算如下所示：\n",
    "F-score =(2 ∗ Precision ∗ Recall)/(Precision+ Recall)，其中：\n",
    "Precision ＝ TP / (TP + FP)，\n",
    "Recall = TP / (TP + FN)。\n",
    "\n",
    "每个异常时刻都有一个真正的根因集合，记为S*，该集合中包含一个或多个属性值组合，参赛队伍的算法输出结果 记为S。\n",
    "对于S*中的每一个元素，S中包含其中一个，则算一次true positive （TP），遗漏一个算一次false negative （FN），\n",
    "多出一个S*中不存在的，记一次false positive （FP）。计算出所有异常时刻总的TP、FP、FN，最后得出F-score。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TP = 0\n",
    "FN = 0\n",
    "FP = 0\n",
    "for ts in result['timestamp'].tolist():\n",
    "    root_cause = result[result['timestamp']==ts]['real_set']\n",
    "    root_cause_cal = result[result['timestamp']==ts]['set']\n",
    "    tmp = 0\n",
    "    for s1 in root_cause:\n",
    "        for s2 in root_cause_cal:\n",
    "            if len(s1) == len(s2) and len(set(s1).intersection(set(s2))) == len(s1):\n",
    "                tmp += 1\n",
    "                break\n",
    "    TP += tmp\n",
    "    FN += len(root_cause) - tmp\n",
    "    FP += len(root_cause_cal) - tmp\n",
    "if TP == 0:\n",
    "    TP += 1\n",
    "print(TP, FP, FN)\n",
    "Precision = TP / (TP + FP)\n",
    "Recall = TP / (TP + FN)\n",
    "FScore = (2 * Precision * Recall)/(Precision + Recall)\n",
    "print('F-score = %f' % FScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
